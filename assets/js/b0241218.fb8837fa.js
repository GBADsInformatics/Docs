"use strict";(self.webpackChunkdocumentation_server=self.webpackChunkdocumentation_server||[]).push([[5279],{3905:(e,t,a)=>{a.d(t,{Zo:()=>p,kt:()=>h});var n=a(7294);function o(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function s(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){o(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function i(e,t){if(null==e)return{};var a,n,o=function(e,t){if(null==e)return{};var a,n,o={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(o[a]=e[a]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(o[a]=e[a])}return o}var l=n.createContext({}),d=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):s(s({},t),e)),a},p=function(e){var t=d(e.components);return n.createElement(l.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},c=n.forwardRef((function(e,t){var a=e.components,o=e.mdxType,r=e.originalType,l=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),c=d(a),h=o,m=c["".concat(l,".").concat(h)]||c[h]||u[h]||r;return a?n.createElement(m,s(s({ref:t},p),{},{components:a})):n.createElement(m,s({ref:t},p))}));function h(e,t){var a=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=a.length,s=new Array(r);s[0]=c;var i={};for(var l in t)hasOwnProperty.call(t,l)&&(i[l]=t[l]);i.originalType=e,i.mdxType="string"==typeof e?e:o,s[1]=i;for(var d=2;d<r;d++)s[d]=a[d];return n.createElement.apply(null,s)}return n.createElement.apply(null,a)}c.displayName="MDXCreateElement"},11:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>u,frontMatter:()=>r,metadata:()=>i,toc:()=>d});var n=a(7462),o=(a(7294),a(3905));const r={sidebar_position:8},s="Data User Guide",i={unversionedId:"Data-Governance-Handbook-for-GBADs/dataUsers",id:"Data-Governance-Handbook-for-GBADs/dataUsers",title:"Data User Guide",description:"Overview",source:"@site/docs/Data-Governance-Handbook-for-GBADs/dataUsers.md",sourceDirName:"Data-Governance-Handbook-for-GBADs",slug:"/Data-Governance-Handbook-for-GBADs/dataUsers",permalink:"/docs/Data-Governance-Handbook-for-GBADs/dataUsers",draft:!1,tags:[],version:"current",sidebarPosition:8,frontMatter:{sidebar_position:8},sidebar:"tutorialSidebar",previous:{title:"Data Contributor Guide",permalink:"/docs/Data-Governance-Handbook-for-GBADs/dataContributors"},next:{title:"Metadata Storage: Graph Databases in GBADs",permalink:"/docs/Data-Governance-Handbook-for-GBADs/metadataStorage"}},l={},d=[{value:"Overview",id:"overview",level:2},{value:"Input data",id:"input-data",level:3},{value:"Output data from models",id:"output-data-from-models",level:3},{value:"Intermediate data sets",id:"intermediate-data-sets",level:3},{value:"Objectives of the Data Usage Guide:",id:"objectives-of-the-data-usage-guide",level:2},{value:"Using the GBADs API",id:"using-the-gbads-api",level:3}],p={toc:d};function u(e){let{components:t,...a}=e;return(0,o.kt)("wrapper",(0,n.Z)({},p,a,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"data-user-guide"},"Data User Guide"),(0,o.kt)("h2",{id:"overview"},"Overview"),(0,o.kt)("p",null,"The data user guide provides GBADs collaborators with an overview of how to access data in the knowledge engine. We have 3 main types of data: "),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"Input data (or raw data)"),(0,o.kt)("li",{parentName:"ol"},"Output data from models "),(0,o.kt)("li",{parentName:"ol"},"Intermediate data sets ")),(0,o.kt)("p",null,"Each type of data and their subsets are uniquely formatted and require specific storage requirements to ensure that the data can be findable, accessible, interoperable and reusable (FAIR); all data must be documented with metadata to ensure that the data is FAIR."),(0,o.kt)("h3",{id:"input-data"},"Input data"),(0,o.kt)("p",null,"Input, or raw data can come in two forms across the GBADs program: "),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Data sets from sources such  as the Food and Agriculture Organization of the United Nations Statistical Database (FAOSTAT), the World Organization for Animal Health (WOAH), national statistics agencies, etc. "),(0,o.kt)("li",{parentName:"ul"},"Parameters obtained from meta-analyses from systematic reviews. "),(0,o.kt)("li",{parentName:"ul"},"Data sets produced from expert elicitation exercises.")),(0,o.kt)("p",null,"These data are the ",(0,o.kt)("em",{parentName:"p"},"inputs")," to the models and calculations that GBADs themes produce. Input data can come in different forms, use varying terminologies and standards for naming countries, species, or other classifications, and thus may have various interpretations of the meaning. "),(0,o.kt)("p",null,"All themes and modellers should be using the same input data that has been cleaned only once to ensure that we are all using the same inputs to models. This ensures reproducibility and accuracy of data across the program. "),(0,o.kt)("h3",{id:"output-data-from-models"},"Output data from models"),(0,o.kt)("p",null,"When models or estimates are produced, they produce parameters and data sets that may be used in subsequent models or estimations. The output data from models and estimates therefore need to be stored in the Knowledge Engine alongside metadata to ensure that all users can understand how the data were populated and produced, including the model code and datasets that were used to populate this data. "),(0,o.kt)("h3",{id:"intermediate-data-sets"},"Intermediate data sets"),(0,o.kt)("p",null,"Intermediate data sets may be data that were produced through a stage in modelling or imputation but are not considered an end product. Intermediate data, however, may be used for other modelling processes and may be important to ensure that the data processes are reproducible. "),(0,o.kt)("h2",{id:"objectives-of-the-data-usage-guide"},"Objectives of the Data Usage Guide:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Understand how to access different types of data in the Knowledge Engine "),(0,o.kt)("li",{parentName:"ul"},"Understand the roles and responsibilities of individuals who have identified a new data set for the use of GBADs program, and how to get this data stored in the Knowledge Engine "),(0,o.kt)("li",{parentName:"ul"},"Understand how to store output data from models in the Knowledge Engine "),(0,o.kt)("li",{parentName:"ul"},"Understand how to search for data stored in the Knowledge Engine")),(0,o.kt)("p",null,"Once you have this 'API call' you can simply input into the program of your choice and automate your workflows and have access to the data without having to search through data catalogues each time. APIs are built on HTTP protocols, providing another plus: you can use APIs with virtually any programming language including R and Python, which are the most popular among our current users. This means that instead of loading data files into your R or python program each time, you can simply access the API right in your program. An added benefit is that this allows you to rerun your programs without having to download data from your sources each time that source is updated or modified."),(0,o.kt)("p",null,"Some data sources that GBADs uses such as FAOSTAT and The World Bank have APIs that can be used to get data. However, GBADs is handling the API management by developing an API that can request data from other APIs ({numref}",(0,o.kt)("inlineCode",{parentName:"p"},"GBADsAPI"),")."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-{figure}",metastring:"/images/GBADsAPI.png","/images/GBADsAPI.png":!0},":name: GBADsAPI\n\nOverview of GBADs API infrastructure. The GBADs API can communicate with various other open APIs to access data from other data stores, such as FAOSTAT. The GBADs API also allows data to be requested from the GBADs data store. Users can access data from various sources through an API call to GBADs API. \n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-{margin}"},"```{admonition} Special Access Data\n:class: tip\n\n_Please note that some data is not publicly available, and therefore is not available to all users_. See [the chapter on Data Licenses, Privacy and Security](http://www.gbadske.org/Documentation/DataGovernanceHandbook/dataOwnership.html) for more information about how GBADs handles confidential and sensitive data. \n```\n")),(0,o.kt)("h3",{id:"using-the-gbads-api"},"Using the GBADs API"),(0,o.kt)("p",null,"You can check out our more extensive API documentation ","[FIXME here]",". However, this section will show you the basics of using our API to fetch some data. "),(0,o.kt)("p",null,"We will provide two examples of API calls to the GBADs API. One in Python, and one in R. In both examples we will use the same API call which will give you stock price of chickens in Ethiopia from 2005 and 2018 from the FAO. Our API call for this type of data is: ",(0,o.kt)("a",{parentName:"p",href:"http://35.183.203.15:8000/gbads/LiveAnimals/?year_start=2005&year_end=2018&element=Stocks&item=Chickens"},"http://35.183.203.15:8000/gbads/LiveAnimals/?year_start=2005&year_end=2018&element=Stocks&item=Chickens")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-{margin}"},"You will notice that if you put the API call directly in your browser you will be brought to a page with the data in JSON format. You'll also notice that the API call specifies the category (LiveAnimals), the start and end year, the element, which are the stock prices and the item, Chickens. Currently our portal only supports the retrieval of Ethiopian data as that is the focus of our pilot study.\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-{note}"},"We are still developing our metadata API. \n")),(0,o.kt)("p",null,"In our Python use case you will need three libraries downloaded: ",(0,o.kt)("inlineCode",{parentName:"p"},"json"),", ",(0,o.kt)("inlineCode",{parentName:"p"},"requests")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"pandas"),".  "),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-{code-cell}",metastring:"ipython3",ipython3:!0},'import json\nimport requests\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Create apiCall\napiCall = "http://15.223.72.239:8000/gbads/LiveAnimals/?year_start=2005&year_end=2018&element=Stocks&item=Chickens"\n\nresponse = requests.get(apiCall).json()\n\n# Print the response so we can see what we got. \nprint(response)\n')),(0,o.kt)("p",null,"In some cases, you may want to convert your response to a ",(0,o.kt)("inlineCode",{parentName:"p"},"pandas")," dataframe, visualize the result, or save the result to a csv file. Below we will demonstrate how you can accomplish each of the following: "),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-{code-cell}",metastring:"ipython3",ipython3:!0},"# Create pandas dataframe from api response\nresponse = pd.DataFrame(response)\n\n# What is our result? Print the first 10 rows of the dataframe.\nprint(response.head(10))\n")),(0,o.kt)("p",null,"Before we go ahead and graph this data, we can use ",(0,o.kt)("inlineCode",{parentName:"p"},"pandas"),"  to get a general overview of the data that we got from the api call."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-{code-cell}",metastring:"ipython3",ipython3:!0},"# Which columns do we have? \nprint(response.columns)\n")),(0,o.kt)("p",null,"We can also see summaries of the columns: "),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-{code-cell}",metastring:"ipython3",ipython3:!0},"response.describe()\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-{code-cell}",metastring:"ipython3",ipython3:!0},"# Graph time!\nresponse.plot.scatter(x='Year',\n    y='Value',\n    c='DarkBlue')\n")),(0,o.kt)("p",null,"And for fun, lets visualize a linear relationship through ",(0,o.kt)("inlineCode",{parentName:"p"},"seaborn"),"'s linear regression function. The function provides a regression line on a plot with a 95% confidence interval. "),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-{code-cell}",metastring:"ipython3",ipython3:!0},'\nax = sns.regplot(x="Year", y="Value", data=response)\n\n# Set axis labels \nax.set(xlabel=\'Year\', ylabel=\'Number of Live Animals (1000 Heads)\')\n\n# Add a title \nplt.title("Number of Live Chickens in Ethiopia")\n\n# Show the result\nplt.show(ax)\n\n')),(0,o.kt)("p",null,"As you can see, with very little work we have gathered the data from the API, converted into a ",(0,o.kt)("inlineCode",{parentName:"p"},"pandas")," dataframe, and plotted a regression. "),(0,o.kt)("p",null,"We could also plot the data and visualize which points correspond to official data, and which were imputted: "),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-{code-cell}",metastring:"python3",python3:!0},'# Different colours for the flag descriptions\nsns.scatterplot(x="Year", y="Value", hue="Flag Description", data=response)\n\n# Set axis labels \nax.set(xlabel=\'Year\', ylabel=\'Number of Live Animals (1000 Heads)\')\n\n# Add a title \nplt.title("Number of Live Chickens in Ethiopia")\n\n# Show the result\nplt.show(ax)\n\n')),(0,o.kt)("p",null,"If you are interested in simply gathering the data from the API and saving it as a csv, you can use the code below to do so."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"import json\nimport requests\nimport pandas as pd\n\n# Create apiCall\napiCall = \"http://15.223.72.239:8000/gbads/LiveAnimals/?year_start=2005&year_end=2018&element=Stocks&item=Chickens\"\n\nresponse = requests.get(apiCall).json()\n\n# Encoding/decoding dataframe to get it in csv format\nresponse = response.to_json(orient='split')\nresponse = pd.read_json(response,orient='split')\n\n# Name of outfile. Replace this with the path to where you would like to store the file, and the filename. \noutfile = 'path/to/outfile/outfilename.csv'\n\n# Save to outfile using pandas \nresponse.to_csv(outfile, index=False)\n")),(0,o.kt)("p",null,"Here's our R implementation: "),(0,o.kt)("p",null,"You will need to make sure that you have the ",(0,o.kt)("inlineCode",{parentName:"p"},"httr")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"jsonlite")," R packages downloaded. "),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},'# Uncomment the line below if you don\'t already have the libraries \n# install.packages(c("httr", "jsonlite"))\n\n# Load in libraries \nlibrary(httr)\nlibrary(jsonlite)\n\n# Create API call\napiCall = "http://15.223.72.239:8000/gbads/LiveAnimals/?year_start=2005&year_end=2018&element=Stocks&item=Chickens"\n\n# Send request\nresponse = GET(apiCall)\n\n# See what the response gives us\nresponse\n\n# Create a dataframe from the API response \ndata = fromJSON(rawToChar(response$content))\n\n# Check to make sure that worked \nclass(data)\n\n# See what the first 5 rows of the data look like \nhead(data)\n')))}u.isMDXComponent=!0}}]);